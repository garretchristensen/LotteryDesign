t_value = stats.t.ppf(0.975, n-2)  # 95% confidence, n-2 degrees of freedom\n",
    "margin_error = t_value * se_regression\n",
    "\n",
    "ci_lower = prediction_2026 - margin_error\n",
    "ci_upper = prediction_2026 + margin_error\n",
    "\n",
    "print(f\"\\n=== 2026 FORECAST ===\")\n",
    "print(f\"Point Estimate: {prediction_2026:,.0f} applications\")\n",
    "print(f\"95% Confidence Interval: {ci_lower:,.0f} - {ci_upper:,.0f}\")\n",
    "print(f\"Margin of Error: ±{margin_error:,.0f}\")\n",
    "\n",
    "# Calculate growth rate from most recent year\n",
    "latest_year = max(years_list)\n",
    "latest_applications = yearly_stats[latest_year]['total_applications']\n",
    "growth_rate = ((prediction_2026 - latest_applications) / latest_applications) * 100\n",
    "\n",
    "print(f\"\\nPredicted growth from {latest_year}: {growth_rate:+.1f}%\")\n",
    "\n",
    "# Model residuals plot for diagnostics\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Residuals vs fitted\n",
    "ax1.scatter(predicted_values, residuals)\n",
    "ax1.axhline(y=0, color='r', linestyle='--')\n",
    "ax1.set_xlabel('Fitted Values')\n",
    "ax1.set_ylabel('Residuals')\n",
    "ax1.set_title('Residuals vs Fitted Values')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot for normality check\n",
    "stats.probplot(residuals, dist=\"norm\", plot=ax2)\n",
    "ax2.set_title('Q-Q Plot (Normality Check)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Demographic Forecasting\n",
    "\n",
    "Let's predict how demographics might change by 2026."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast demographic trends\n",
    "demographic_forecasts = {}\n",
    "\n",
    "demographics_to_forecast = ['avg_age', 'female_percent']\n",
    "if 'avg_previous_apps' in summary_df.columns:\n",
    "    demographics_to_forecast.append('avg_previous_apps')\n",
    "\n",
    "print(\"=== DEMOGRAPHIC FORECASTS FOR 2026 ===\")\n",
    "\n",
    "for demographic in demographics_to_forecast:\n",
    "    if demographic in summary_df.columns:\n",
    "        # Get the data\n",
    "        y_demo = np.array(summary_df[demographic])\n",
    "        \n",
    "        # Fit linear model\n",
    "        demo_model = LinearRegression()\n",
    "        demo_model.fit(years_array, y_demo)\n",
    "        \n",
    "        # Predict 2026\n",
    "        prediction_demo = demo_model.predict([[2026]])[0]\n",
    "        \n",
    "        # Calculate change from most recent year\n",
    "        current_value = yearly_stats[latest_year][demographic]\n",
    "        change = prediction_demo - current_value\n",
    "        \n",
    "        # Store results\n",
    "        demographic_forecasts[demographic] = {\n",
    "            'current': current_value,\n",
    "            'predicted': prediction_demo,\n",
    "            'change': change,\n",
    "            'r2': r2_score(y_demo, demo_model.predict(years_array))\n",
    "        }\n",
    "        \n",
    "        # Pretty names for output\n",
    "        name_map = {\n",
    "            'avg_age': 'Average Age',\n",
    "            'female_percent': 'Female Participation (%)',\n",
    "            'avg_previous_apps': 'Average Previous Applications'\n",
    "        }\n",
    "        \n",
    "        pretty_name = name_map.get(demographic, demographic)\n",
    "        \n",
    "        print(f\"\\n{pretty_name}:\")\n",
    "        print(f\"  {latest_year}: {current_value:.1f}\")\n",
    "        print(f\"  2026: {prediction_demo:.1f} ({change:+.1f})\")\n",
    "        print(f\"  Model R²: {demographic_forecasts[demographic]['r2']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Forecast Visualization\n",
    "\n",
    "Let's create a comprehensive visualization showing our forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecast visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Historical data\n",
    "ax.plot(years_list, summary_df['total_applications'], 'o-', \n",
    "        linewidth=3, markersize=10, label='Historical Data', color='blue')\n",
    "\n",
    "# Trend line\n",
    "trend_years = list(range(min(years_list), 2027))\n",
    "trend_values = [model.predict([[year]])[0] for year in trend_years]\n",
    "ax.plot(trend_years, trend_values, '--', \n",
    "        linewidth=2, alpha=0.7, label='Linear Trend', color='gray')\n",
    "\n",
    "# 2026 prediction\n",
    "ax.plot(2026, prediction_2026, 'ro', markersize=15, label='2026 Prediction')\n",
    "\n",
    "# Confidence interval\n",
    "ax.errorbar(2026, prediction_2026, yerr=margin_error, \n",
    "           fmt='r', capsize=10, capthick=2, label='95% Confidence Interval')\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Year', fontsize=12)\n",
    "ax.set_ylabel('Number of Applications', fontsize=12)\n",
    "ax.set_title('Ultramarathon Lottery Applications: Historical Trends & 2026 Forecast', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "# Add annotation with key statistics\n",
    "annotation_text = f\"\"\"2026 Forecast: {prediction_2026:,.0f} applications\n",
    "95% CI: {ci_lower:,.0f} - {ci_upper:,.0f}\n",
    "Growth from {latest_year}: {growth_rate:+.1f}%\n",
    "Model R²: {r2:.3f}\"\"\"\n",
    "\n",
    "ax.text(0.02, 0.98, annotation_text, transform=ax.transAxes, \n",
    "        fontsize=10, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Alternative Models and Robustness Checks\n",
    "\n",
    "Let's test some alternative forecasting approaches to see how robust our predictions are."\n{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultramarathon Lottery Analysis & 2026 Forecasting\n",
    "\n",
    "This notebook analyzes historical ultramarathon lottery application data to predict 2026 application volumes and demographic trends.\n",
    "\n",
    "**Author:** [Your Name]  \n",
    "**Date:** January 2025  \n",
    "**Data:** Hardrock 100 lottery applications (2022-2025)\n",
    "\n",
    "## Methodology Overview\n",
    "\n",
    "We'll use several econometric approaches:\n",
    "- **Linear trend analysis** (OLS regression on time)\n",
    "- **Demographic trend modeling** (separate models for age, gender, experience)\n",
    "- **Bootstrap confidence intervals** for uncertainty quantification\n",
    "- **Model validation** using R² and residual analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup\n",
    "\n",
    "First, we'll import the Python libraries we need. Think of this like loading packages in R with `library()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis (like dplyr + data.table in R)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization (like ggplot2)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical modeling (like lm() function in R)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# For statistical tests and distributions\n",
    "from scipy import stats\n",
    "\n",
    "# Set up plotting preferences\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"✓ Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Exploration\n",
    "\n",
    "Now we'll load our CSV files. In R, this would be like using `read.csv()`. We'll try different encodings to handle any file format issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the years we have data for\n",
    "years = [2022, 2023, 2024, 2025]  # Adjust this list based on your files\n",
    "datasets = {}  # This will store our dataframes (like a list in R)\n",
    "\n",
    "print(\"Loading lottery application data...\\n\")\n",
    "\n",
    "for year in years:\n",
    "    filename = f'{year}HLdata.csv'\n",
    "    \n",
    "    # Try different encodings (similar to specifying encoding in R's read.csv)\n",
    "    for encoding in ['utf-8', 'cp1252', 'latin1']:\n",
    "        try:\n",
    "            df = pd.read_csv(filename, encoding=encoding)\n",
    "            datasets[year] = df\n",
    "            print(f\"✓ {year}: Loaded {len(df):,} applications ({encoding} encoding)\")\n",
    "            break\n",
    "        except FileNotFoundError:\n",
    "            print(f\"✗ {filename} not found\")\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error loading {year}: {e}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Structure Examination\n",
    "\n",
    "Let's examine our data structure - similar to `str()` and `summary()` in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the structure of our datasets\n",
    "for year, df in datasets.items():\n",
    "    print(f\"\\n=== {year} Dataset Structure ===\")\n",
    "    print(f\"Dimensions: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Show first few rows (like head() in R)\n",
    "    print(\"\\nFirst 3 rows:\")\n",
    "    print(df.head(3))\n",
    "    \n",
    "    # Check for missing data (like is.na() in R)\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(\"\\nMissing values:\")\n",
    "        print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning and Standardization\n",
    "\n",
    "Before analysis, we need to clean the data. This is similar to data preprocessing in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and standardize the data\n",
    "cleaned_datasets = {}\n",
    "\n",
    "for year, df in datasets.items():\n",
    "    print(f\"\\nCleaning {year} data...\")\n",
    "    \n",
    "    # Make a copy to avoid modifying original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Remove rows with missing essential data (like na.omit() in R)\n",
    "    essential_cols = ['Age', 'Gender']\n",
    "    before_count = len(df_clean)\n",
    "    \n",
    "    for col in essential_cols:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean = df_clean.dropna(subset=[col])\n",
    "    \n",
    "    # Remove invalid ages (basic data validation)\n",
    "    if 'Age' in df_clean.columns:\n",
    "        df_clean = df_clean[(df_clean['Age'] > 0) & (df_clean['Age'] < 100)]\n",
    "    \n",
    "    after_count = len(df_clean)\n",
    "    \n",
    "    # Standardize gender values (like factor() with levels in R)\n",
    "    if 'Gender' in df_clean.columns:\n",
    "        df_clean['Gender'] = df_clean['Gender'].astype(str).str.strip().str.title()\n",
    "        # Standardize common variations\n",
    "        df_clean['Gender'] = df_clean['Gender'].replace({\n",
    "            'F': 'Female', 'M': 'Male', \n",
    "            'Woman': 'Female', 'Man': 'Male'\n",
    "        })\n",
    "    \n",
    "    cleaned_datasets[year] = df_clean\n",
    "    print(f\"  Cleaned: {before_count:,} → {after_count:,} rows ({before_count-after_count:,} removed)\")\n",
    "\n",
    "print(\"\\n✓ Data cleaning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Descriptive Statistics by Year\n",
    "\n",
    "Let's calculate summary statistics for each year. This is like using `aggregate()` or `group_by() %>% summarise()` in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate yearly statistics\n",
    "yearly_stats = {}\n",
    "\n",
    "for year, df in cleaned_datasets.items():\n",
    "    stats = {\n",
    "        'total_applications': len(df),\n",
    "        'avg_age': df['Age'].mean(),\n",
    "        'median_age': df['Age'].median(),\n",
    "        'age_std': df['Age'].std(),\n",
    "        'min_age': df['Age'].min(),\n",
    "        'max_age': df['Age'].max()\n",
    "    }\n",
    "    \n",
    "    # Gender distribution (like table() in R)\n",
    "    if 'Gender' in df.columns:\n",
    "        gender_counts = df['Gender'].value_counts()\n",
    "        total = len(df)\n",
    "        stats['female_count'] = gender_counts.get('Female', 0)\n",
    "        stats['male_count'] = gender_counts.get('Male', 0)\n",
    "        stats['female_percent'] = (stats['female_count'] / total) * 100\n",
    "        stats['male_percent'] = (stats['male_count'] / total) * 100\n",
    "    \n",
    "    # Experience metrics\n",
    "    if 'Previous_Applications' in df.columns:\n",
    "        stats['avg_previous_apps'] = df['Previous_Applications'].fillna(0).mean()\n",
    "        stats['median_previous_apps'] = df['Previous_Applications'].fillna(0).median()\n",
    "    \n",
    "    if 'Volunteer_Shifts' in df.columns:\n",
    "        volunteer_data = df['Volunteer_Shifts'].dropna()\n",
    "        if len(volunteer_data) > 0:\n",
    "            stats['avg_volunteer_shifts'] = volunteer_data.mean()\n",
    "            stats['median_volunteer_shifts'] = volunteer_data.median()\n",
    "        else:\n",
    "            stats['avg_volunteer_shifts'] = 0\n",
    "            stats['median_volunteer_shifts'] = 0\n",
    "    \n",
    "    yearly_stats[year] = stats\n",
    "\n",
    "# Display results in a nice format\n",
    "print(\"=== YEARLY SUMMARY STATISTICS ===\\n\")\n",
    "\n",
    "for year in sorted(yearly_stats.keys()):\n",
    "    stats = yearly_stats[year]\n",
    "    print(f\"{year}:\")\n",
    "    print(f\"  Total Applications: {stats['total_applications']:,}\")\n",
    "    print(f\"  Age: {stats['avg_age']:.1f} ± {stats['age_std']:.1f} (mean ± SD)\")\n",
    "    print(f\"  Age Range: {stats['min_age']:.0f} - {stats['max_age']:.0f}\")\n",
    "    if 'female_percent' in stats:\n",
    "        print(f\"  Gender: {stats['female_percent']:.1f}% Female, {stats['male_percent']:.1f}% Male\")\n",
    "    if 'avg_previous_apps' in stats:\n",
    "        print(f\"  Experience: {stats['avg_previous_apps']:.1f} avg previous applications\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trend Visualization\n",
    "\n",
    "Let's create some visualizations to understand the trends. This is like using `ggplot()` in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary dataframe for plotting (like data.frame() in R)\n",
    "years_list = sorted(yearly_stats.keys())\n",
    "summary_df = pd.DataFrame(yearly_stats).T  # Transpose to get years as rows\n",
    "summary_df.index.name = 'Year'\n",
    "\n",
    "print(\"Summary statistics by year:\")\n",
    "print(summary_df[['total_applications', 'avg_age', 'female_percent', 'avg_previous_apps']].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization dashboard\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Ultramarathon Lottery Trends Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Total applications trend\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(years_list, summary_df['total_applications'], 'o-', linewidth=3, markersize=8)\n",
    "ax1.set_title('Total Applications by Year')\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Number of Applications')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(years_list, summary_df['total_applications'], 1)\n",
    "p = np.poly1d(z)\n",
    "ax1.plot(years_list, p(years_list), \"r--\", alpha=0.8, label=f'Trend (slope: {z[0]:.0f}/year)')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Average age trend\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(years_list, summary_df['avg_age'], 's-', color='green', linewidth=3, markersize=8)\n",
    "ax2.set_title('Average Age Trend')\n",
    "ax2.set_xlabel('Year')\n",
    "ax2.set_ylabel('Average Age')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Female participation trend\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(years_list, summary_df['female_percent'], '^-', color='purple', linewidth=3, markersize=8)\n",
    "ax3.set_title('Female Participation Trend')\n",
    "ax3.set_xlabel('Year')\n",
    "ax3.set_ylabel('Female Percentage (%)')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Experience level trend\n",
    "ax4 = axes[1, 1]\n",
    "if 'avg_previous_apps' in summary_df.columns:\n",
    "    ax4.plot(years_list, summary_df['avg_previous_apps'], 'd-', color='orange', linewidth=3, markersize=8)\n",
    "    ax4.set_title('Experience Level Trend')\n",
    "    ax4.set_xlabel('Year')\n",
    "    ax4.set_ylabel('Avg Previous Applications')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "else:\n",
    "    ax4.text(0.5, 0.5, 'Previous Applications\\ndata not available', \n",
    "             transform=ax4.transAxes, ha='center', va='center')\n",
    "    ax4.set_title('Experience Data Not Available')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Statistical Modeling and Forecasting\n",
    "\n",
    "Now we'll build our forecasting models. This is similar to using `lm()` in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "years_array = np.array(years_list).reshape(-1, 1)  # X variable (predictor)\n",
    "applications_array = np.array(summary_df['total_applications'])  # Y variable (outcome)\n",
    "\n",
    "print(\"=== LINEAR REGRESSION MODEL ===\")\n",
    "print(f\"Data points: {len(years_list)} years\")\n",
    "print(f\"Years: {years_list}\")\n",
    "print(f\"Applications: {list(applications_array)}\")\n",
    "\n",
    "# Fit linear regression model (like lm(applications ~ year) in R)\n",
    "model = LinearRegression()\n",
    "model.fit(years_array, applications_array)\n",
    "\n",
    "# Get model parameters\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "r2 = r2_score(applications_array, model.predict(years_array))\n",
    "\n",
    "print(f\"\\nModel: Applications = {intercept:.1f} + {slope:.1f} × Year\")\n",
    "print(f\"R² = {r2:.3f} (explains {r2*100:.1f}% of variance)\")\n",
    "\n",
    "# Calculate prediction for 2026\n",
    "prediction_2026 = model.predict([[2026]])[0]\n",
    "\n",
    "print(f\"\\n2026 Prediction: {prediction_2026:,.0f} applications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Confidence Intervals and Model Diagnostics\n",
    "\n",
    "Let's calculate confidence intervals and check our model assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals and standard errors\n",
    "predicted_values = model.predict(years_array)\n",
    "residuals = applications_array - predicted_values\n",
    "\n",
    "# Standard error of regression\n",
    "n = len(years_list)\n",
    "mse = np.sum(residuals**2) / (n - 2)  # Mean squared error\n",
    "se_regression = np.sqrt(mse)\n",
    "\n",
    "print(\"=== MODEL DIAGNOSTICS ===\")\n",
    "print(f\"Standard Error of Regression: {se_regression:.1f}\")\n",
    "print(f\"Mean Absolute Error: {np.mean(np.abs(residuals)):.1f}\")\n",
    "\n",
    "# Calculate 95% confidence interval for 2026 prediction\n",
    "# This is a simplified calculation - in practice you'd use t-distribution\n",
    "t_value = stats.t.ppf(0.975, n-2)  # 95% confidence, n-2 degrees of freedom